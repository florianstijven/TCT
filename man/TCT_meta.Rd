% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/time_scale_effects.R
\name{TCT_meta}
\alias{TCT_meta}
\title{Transform vertical Treatment Effect Estimates to the Time Scale}
\usage{
TCT_meta(
  time_points,
  ctrl_estimates,
  exp_estimates,
  vcov,
  interpolation = "spline",
  inference = "least-squares",
  B = 0,
  constraints = FALSE
)
}
\arguments{
\item{time_points}{Ordered vector that contains the times corresponding to
the estimated means in the \code{ctrl_estimates} vector. The first element
should be zero and correspond to the time of randomization.}

\item{ctrl_estimates}{Estimated mean outcome in the control group at the
fixed occasions corresponding to the times in \code{time_points}.}

\item{exp_estimates}{Estimated mean outcomes in the experimental group at
fixed occasions corresponding to the times in \code{time_points[-1]}. Note that
first element in \code{exp_estimates} should correspond to some time after
randomization.}

\item{vcov}{The variance-covariance matrix for the means. In order to map to
the correct estimates, this matrix should be the variance-covariance matrix
of \code{c(ctrl_means, exp_means)}. If an element of \code{c(ctrl_means, exp_means)}
is known (e.g., mean at baseline is zero when using change from baseline as
outcome), then the corresponding row and column in \code{vcov} should be set to
zero.}

\item{interpolation}{Which interpolation method to use?
\itemize{
\item \code{"linear"}: linear interpolation.
\item \code{"spline"}: natural cubic spline interpolation. This interpolation method has been most
thoroughly tested is most stable.
\item \verb{"monoH.FC}: monotone Hermite spline according to the method of Fritsch
and Carlson.
}}

\item{inference}{Which approach is used for estimation and inference? Should
be \code{"least-squares"}, \code{"contrast"}or \code{"delta-method"}.}

\item{B}{Number of parametric bootstrap replications. If \code{B = 0}, no
bootstrap is performed (default).}

\item{constraints}{Use the constrained generalized least squares estimator
for the vertical treatment effects.}
}
\value{
S3 object of class \code{"TCT_meta"}
}
\description{
The \code{\link[=TCT_meta]{TCT_meta()}} function transforms so-called vertical parameter estimates
to parameter estimates on the time scale. These treatment effect estimates on
the time scale are so-called acceleration factors. This is an application of
the Time-Component Test (TCT) methodology.
}
\section{Time-Component Tests}{
Time-component tests (TCT) constitutes a general methodology to evaluating
treatment effects with longitudinal data on the time scale. Conventional
treatment effects with longitudinal data are so-called vertical treatment
effects; these are comparisons of group means (or other summary measures like
the median) at fixed measurement occasions. Throughout the documentation, we
assumed that the mean is the summary measure of interest.

Let \eqn{\boldsymbol{t} = (t_0 = 0, t_1, ..., t_K)'} be the fixed measurement
occasions (\code{timepoints} in this function). Let \eqn{\boldsymbol{\alpha} =
(\alpha_0, \alpha_1, ..., \alpha_K)'} be the corresponding means in the
control group. Let \eqn{\boldsymbol{\beta} = (\beta_1, ..., \beta_{K})} be
the corresponding means in the experimental group. Note that the index starts
here at 1, i.e., the first measurement \emph{after} start of the treatment. Let
the mean trajectory in the control and experimental group be, respectively,
\eqn{E(Y_t(0)) =: f_0(t; \boldsymbol{\alpha})} and \eqn{E(Y_t(0)) =: f_1(t; \boldsymbol{\beta})},
where \eqn{E(Y_t(z))} is the potential outcome at time \eqn{t} under treatment
\eqn{z} (0 for control, 1 for experimental group).

The treatment effects on the time scale are acceleration factors, analogous
to accelerated failure time models. These are defined as follows at
\eqn{t_j}, \deqn{f_1(t; \boldsymbol{\beta}) = f_0(\gamma_j \cdot t;
\boldsymbol{\alpha})}
where \eqn{\gamma_j} is the so-called time-specific acceleration factor at \eqn{t_j}, i.e.,
treatment causes an acceleration of \eqn{\gamma_j}. For example, if
\eqn{\gamma_j = 0.5}, patients in the active treatment group progress half as
slow as patients in the control group. The time-specific acceleration factors
are estimated by the \code{\link[=TCT_meta]{TCT_meta()}} function. Also note that no testable assumptions
are required for estimating the time-specific acceleration factors.

One may assume that \eqn{\gamma_j = \gamma} for all \eqn{j}, which
corresponds to proportional slowing (or a constant acceleration factor in
accelerated-failure time model terminology). The \code{\link[=TCT_meta_common]{TCT_meta_common()}} function
estimates the common acceleration factor under the assumption of proportional
slowing. Estimating the common acceleration factor may be more efficient than
estimating time-specific acceleration factors and leads to a more
parsimonious interpretation of the treatment effect, but this relies on the
proportional slowing assumption. This is a testable assumption, a test for
which is automatically performed by \code{\link[=TCT_meta_common]{TCT_meta_common()}}.
}

\section{Estimation and Inference}{
Following options for estimation and inference are available:
\itemize{
\item Least-squares based estimation and inference. More information in \code{\link[=nonlinear_gls_estimator]{nonlinear_gls_estimator()}}.
\item Contrast-based estimation and inference: More information in \code{\link[=contrast_test]{contrast_test()}} and
\code{\link[=contrast_test_common]{contrast_test_common()}}. For estimation and inference about time-specific acceleration factors,
this is equivalent to least squares (but not for the common acceleration factor).
\item Parametric bootstrap. More information in
\code{\link[=pm_bootstrap_vertical_to_horizontal]{pm_bootstrap_vertical_to_horizontal()}}. If \code{B > 1} then the parametric
bootstrap is performed.
\item Delta method. More information in \code{\link[=DeltaMethod]{DeltaMethod()}}. This approach to inference
is not recommended, but is available for completeness.
}

Note that the estimators for the time-specific acceleration factors in the
above methods are equivalent. The difference lies in the procedures to
computing standard errors, p-values, and confidence intervals.
}

\examples{
# transform example data set to desired format
library(dplyr)
data = simulated_test_trial \%>\%
mutate(time_int = (Week \%/\% 25)) \%>\%
  arrange(trial_number, SubjId, time_int) \%>\%
  mutate(time_int = as.integer(time_int) + 1L) \%>\%
  mutate(arm_time = ifelse(time_int == 1L,
                           "baseline",
                           paste0(arm, ":", time_int)))
# fit e.g. MMRM model to obtain estimates of profiles
mmrm_fit = analyze_mmrm(data)
set.seed(1)
TCT_Fit = TCT_meta(
  time_points = 0:4,
  ctrl_estimates = coef(mmrm_fit)[c(9, 1:4)],
  exp_estimates = coef(mmrm_fit)[5:8],
  vcov = vcov(mmrm_fit)[c(9, 1:4, 5:8), c(9, 1:4, 5:8)],
  interpolation = "spline",
  B = 1e3
)
# The summary() generic can be used to obtain the most useful quantities from
# the Meta-TCT.
summary(TCT_Fit)
}
