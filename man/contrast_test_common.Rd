% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/contrast-test.R
\name{contrast_test_common}
\alias{contrast_test_common}
\title{contrast test for common acceleration factor}
\usage{
contrast_test_common(
  time_points,
  ctrl_estimates,
  exp_estimates,
  ref_fun,
  interpolation,
  vcov,
  gamma_0 = 1,
  type = "omnibus",
  j = 1:length(exp_estimates),
  weights = NULL
)
}
\arguments{
\item{time_points}{Ordered vector that contains the times corresponding to
the estimated means in the \code{ctrl_estimates} vector. The first element
should be zero and correspond to the time of randomization.}

\item{ctrl_estimates}{Estimated mean outcome in the control group at the
fixed occasions corresponding to the times in \code{time_points}.}

\item{exp_estimates}{Estimated mean outcomes in the experimental group at
fixed occasions corresponding to the times in \code{time_points[-1]}. Note that
first element in \code{exp_estimates} should correspond to some time after
randomization.}

\item{ref_fun}{Intra- and extrapolation function that is returned by
\code{ref_fun_constructor()}.}

\item{interpolation}{Which interpolation method to use?
\itemize{
\item \code{"linear"}: linear interpolation.
\item \code{"spline"}: natural cubic spline interpolation. This interpolation method has been most
thoroughly tested is most stable.
\item \verb{"monoH.FC}: monotone Hermite spline according to the method of Fritsch
and Carlson.
}}

\item{vcov}{The variance-covariance matrix for the means. In order to map to
the correct estimates, this matrix should be the variance-covariance matrix
of \code{c(ctrl_means, exp_means)}. If an element of \code{c(ctrl_means, exp_means)}
is known (e.g., mean at baseline is zero when using change from baseline as
outcome), then the corresponding row and column in \code{vcov} should be set to
zero.}

\item{gamma_0}{Value for the acceleration factor under the null hypothesis.}

\item{type}{Which type of test statistic should be used. See Test Statistic
Variants. Should be one of
\enumerate{
\item \code{type = "omnibus"}
\item \code{type = "directional"}
\item \code{type = "inverse variance"}
\item \code{type = "custom"}
}}

\item{j}{(Integer) vector that indicates which elements in \code{exp_estimates}
should be used for the contrast test. Defaults to \code{1:length(exp_estimates)},
i.e., all elements are used.}

\item{weights}{If \code{type == "custom"}, the user should specify a weight
vector for weighting estimates at different time points differently.}
}
\value{
Named (numeric) vector with two elements:
\enumerate{
\item \code{"z"} or \code{"chi-squared"}. The test statistic.
\item \code{"p-value"}: two-sided p-value.
}
}
\description{
The \code{\link[=contrast_test_common]{contrast_test_common()}} function implements the contrast test under the
assumption that there exists a common acceleration factor. Multiple variants
to this test exist and are implemented.
}
\section{Test Statistic Variants}{
Two types of test statistics are implemented in the \code{\link[=contrast_test_common]{contrast_test_common()}}
function:
\enumerate{
\item \code{type = "omnibus"}
\item \code{type = "custom"}
}

These are discussed in more detail next.
\subsection{Omnibus}{

The omnibus contrast test is based on the "classic" chi-squared statistic that is
defined as follows,
\deqn{t^2 = \boldsymbol{s}(\gamma_0 \cdot \boldsymbol{t}; \hat{\boldsymbol{\alpha}}, \hat{\boldsymbol{\beta}})^t \cdot \Sigma_s^{-1} \cdot \boldsymbol{s}(\gamma_0 \cdot \boldsymbol{t}; \hat{\boldsymbol{\alpha}}, \hat{\boldsymbol{\beta}}).}
which follows a chi-squared distribution with K degrees of freedom under
\eqn{H_{\gamma_0}} for all time points. An important feature of this test
statistic is that it reduces to the chi-squared statistic for \eqn{H_0 :
\alpha_j = \beta_j} for all \eqn{j} in \code{j} when \code{gamma_0 = 1}. However, this
also means that there is no gain in power.
}

\subsection{Custom}{

The "custom" contrast test allows for user-specified weights, \eqn{w}. The test
statistic is defined as follows,
\deqn{z = \frac{v(\hat{\boldsymbol{\alpha}}, \hat{\boldsymbol{\beta}}; \gamma_0)}{\sqrt{\boldsymbol{w}^t \Sigma_s \boldsymbol{w}}} \; \dot\sim \; N(0, 1).}
As indicated above, this test statistic follows a standard normal
distribution under the null hypothesis.

Note that \code{\link[=optimize_weights]{optimize_weights()}} allows one to find optimal weights in the
sense of minimizing the estimated standard error for the corresponding
estimator of the common acceleration factor.
}
}

\section{Contrast Test}{
For constructing a contrast test, we start from the null hypothesis,
\deqn{H_{\gamma_0}: \gamma_j = \gamma_0,} where \eqn{\gamma_j} is the
acceleration factor at time \eqn{t_j}. Under this null hypothesis, and taking
the control group as reference, we can
compute the experimental treatment group mean at \eqn{t_j} as \deqn{\beta_{0,
j} = f_0( \gamma_0 \cdot t_{j}; \boldsymbol{\alpha})} given the true control
group mean vector, \eqn{\boldsymbol{\alpha}}. Consequently, a test for
\eqn{H_0: \beta_j = \beta_{0, j}} is also a valid test for
\eqn{H_{\gamma_0}}. Well-established tests are available for the former
hypothesis. However, these cannot be applied directly since
\eqn{\boldsymbol{\alpha}} is not known, but only estimated. Indeed, \eqn{\beta_{0,
j}} is itself estimated by \eqn{\hat{\beta}_{0, j} =  f_0( \gamma_0 \cdot t_{j};
\hat{\boldsymbol{\alpha}})}. Still, this provides the starting point for a
contrast test that draws upon well-established statistical tests.

We first define the contrast vector as follows, \deqn{\boldsymbol{\Phi}(\boldsymbol{\gamma}; \hat{\boldsymbol{\alpha}}_n, \hat{\boldsymbol{\beta}}_n) =
\hat{\boldsymbol{\beta}}_n - \left(f_0(\gamma_1 \cdot t_1;
\hat{\boldsymbol{\alpha}}_n), \dots, f_0(\gamma_K \cdot t_K;
\hat{\boldsymbol{\alpha}}_n)\right)^\top.}
Under \eqn{H_{\gamma_0}} for all time points and using the delta
method, we have that
\deqn{n^{1/2}\boldsymbol{\Phi}(\boldsymbol{\gamma_0}; \hat{\boldsymbol{\alpha}}_n,
\hat{\boldsymbol{\beta}}_n) \overset{d}{\to} \mathcal{N}(\boldsymbol{0}, \Omega)} where
\deqn{\Omega =
\dot{\boldsymbol{\Phi}}_{\boldsymbol{\alpha}, \boldsymbol{\beta}}(\boldsymbol{\gamma_0}; \boldsymbol{\alpha_0}, \boldsymbol{\beta_0}) \cdot \Sigma \cdot
\dot{\boldsymbol{\Phi}}_{\boldsymbol{\alpha}, \boldsymbol{\beta}}(\boldsymbol{\gamma_0}; \boldsymbol{\alpha_0}, \boldsymbol{\beta_0})^\top} with
\eqn{\dot{\boldsymbol{\Phi}}_{\boldsymbol{\alpha}, \boldsymbol{\beta}}(\boldsymbol{\gamma_0}; \boldsymbol{\alpha_0}, \boldsymbol{\beta_0})} the
Jacobian of \eqn{(\boldsymbol{\alpha}, \boldsymbol{\beta}) \mapsto \boldsymbol{\Phi}(\boldsymbol{\gamma_0}; \boldsymbol{\alpha}, \boldsymbol{\beta})} evaluated in the true parameter vector,
\eqn{(\boldsymbol{\alpha_0}, \boldsymbol{\beta_0})'}.
In practice, \eqn{\Omega} is unknown because the true parameter vector is unknown.
We, therefore, replace the unkown parameters wit the corresponding estimates in
the above expression for \eqn{\Omega}; the corresponding estimated matrix is
denoted by \eqn{\hat{\Omega}_n}. As long as \eqn{\hat{\Omega}_n} is consistent
for \eqn{\Omega}, we have the following distributional result, which forms the
basis for hypothesis tests and confidence intervals:
\deqn{n^{1/2}\boldsymbol{\Phi}(\boldsymbol{\gamma_0}; \hat{\boldsymbol{\alpha}}_n,
\hat{\boldsymbol{\beta}}_n) \overset{d}{\to} \mathcal{N}(\boldsymbol{0}, \hat{\Omega}_n).}
Specifically, for tests for time-specific acceleration factors, we use the
following distributional result:
\deqn{n^{1/2}\Phi_j(\gamma_0; \hat{\boldsymbol{\alpha}}_n,
\hat{\boldsymbol{\beta}}_n) \overset{d}{\to} \mathcal{N}(\boldsymbol{0}, \hat{\Omega}_n)}
where
}

